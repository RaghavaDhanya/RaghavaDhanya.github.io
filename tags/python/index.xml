<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Python on AI Logs</title><link>https://ai.ragv.in/tags/python/</link><description>Recent content in Python on AI Logs</description><generator>Hugo -- 0.140.2</generator><language>en-us</language><copyright>2023 Raghava Dhanya | License |</copyright><lastBuildDate>Tue, 14 Nov 2023 11:54:11 +0530</lastBuildDate><atom:link href="https://ai.ragv.in/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>Keeping Configurations Sane with Pydantic Settings</title><link>https://ai.ragv.in/posts/sane-configs-with-pydantic-settings/</link><pubDate>Tue, 14 Nov 2023 11:54:11 +0530</pubDate><guid>https://ai.ragv.in/posts/sane-configs-with-pydantic-settings/</guid><description>&lt;p>Configurations are a crucial aspect of any software project. There are many sources of configurations, such as environment variables, configuration files, and command-line arguments. For file-based configurations in python, YAML and TOML (or INI) are popular choices. I prefer YAML, though it is not without flaws, some of which can be addressed by Pydantic anyway like type safety etc.&lt;/p>
&lt;p>Pydantic is a data validation library for Python. It is built on top of Python type hints and provides runtime validation of data. Pydantic is widely used for data validation for APIs, but it can also be used for configuration management. Pydantic has a settings management library called &lt;code>pydantic-settings&lt;/code> that makes it easy to load configurations from multiple sources.&lt;/p></description></item><item><title>Designing Machine Learning Systems for High Velocity Trading</title><link>https://ai.ragv.in/posts/high-velocity-trading-ml-systems/</link><pubDate>Tue, 20 Jun 2023 21:31:48 +0530</pubDate><guid>https://ai.ragv.in/posts/high-velocity-trading-ml-systems/</guid><description>&lt;p>As one of my works at &lt;a href="https://www.mu-sigma.com/labs">Mu Sigma Labs&lt;/a>, I was part of a research project on the High Velocity Time Series on early 2019. One of the goals was to create a high velocity trading app using Pair Trading.&lt;/p>
&lt;h2 id="the-requisite-terms">The Requisite terms&lt;/h2>
&lt;h3 id="long-and-short-trades">Long and Short trades&lt;/h3>
&lt;p>Long trades are buying a &lt;a href="https://en.wikipedia.org/wiki/Security_(finance)">security&lt;/a>. Short is selling a security even when you don&amp;rsquo;t own it. It generally means that you are borrowing someone&amp;rsquo;s securities and selling them in the hopes of buying it back for lower cost later and returning it and hence, making a profit. You don&amp;rsquo;t really have to do it though; exchanges take care of it and let you sell when you don&amp;rsquo;t own a security.&lt;/p></description></item><item><title>Python with a Dash of C++: Optimizing Recommendation Serving</title><link>https://ai.ragv.in/posts/python-with-a-dash-of-cpp-optimizing/</link><pubDate>Thu, 30 Jun 2022 16:54:09 +0530</pubDate><guid>https://ai.ragv.in/posts/python-with-a-dash-of-cpp-optimizing/</guid><description>&lt;p>Serving recommendation to 200+ millions of users for thousands of candidates with less than 100ms is &lt;strong>hard&lt;/strong> but doing that in Python is &lt;strong>harder&lt;/strong>. Why not add some compiled spice to it to make it faster? Using Cython you can add C++ components to your Python code. Isn&amp;rsquo;t all machine learning and statistics libraries already written in C and Cython to make them super fast? Yes. But there&amp;rsquo;s still some optimizations left on the table. I&amp;rsquo;ll go through how I optimized some of our sampling methods in the recommendation system using C++.&lt;/p></description></item><item><title>Go faster with Go: Golang for ML Serving</title><link>https://ai.ragv.in/posts/golang-for-machine-learning-serving/</link><pubDate>Mon, 20 Jun 2022 21:36:00 +0530</pubDate><guid>https://ai.ragv.in/posts/golang-for-machine-learning-serving/</guid><description>&lt;p>So the ask is to do &lt;strong>3 Million Predictions per second&lt;/strong> with as little resources as possible. Thankfully its one of the simpler model of Recommendation systems, Multi Armed Bandit(MAB).
Multi Armed bandit usually involves sampling from distribution like &lt;a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta Distribution&lt;/a>. That&amp;rsquo;s where the most time is spent. If we can concurrently do as many sampling as we can, we&amp;rsquo;ll use the resources well. Maximizing Resource utilization is the key to reducing overall resources needed for the model.&lt;/p></description></item><item><title>Showcase: BPMN Pipeline Platform</title><link>https://ai.ragv.in/posts/bpmn-pipeline-platform/</link><pubDate>Mon, 20 Jun 2022 20:54:07 +0530</pubDate><guid>https://ai.ragv.in/posts/bpmn-pipeline-platform/</guid><description>&lt;p>At &lt;a href="https://www.mu-sigma.com/labs">Mu Sigma Labs&lt;/a>, I led a significant project focused on BPMN-based analytics automation and pipeline orchestration. Using the open-source platform &lt;a href="https://www.activiti.org/">Activiti&lt;/a>, I owned, developed, tested, and maintained a system serving about &lt;em>3,000&lt;/em> internal users, handling &lt;em>critical&lt;/em> reporting and data pipelines.&lt;/p>
&lt;h3 id="technologies-used">Technologies Used&lt;/h3>
&lt;p>The core technologies employed were:&lt;/p>
&lt;ul>
&lt;li>Backend: Java and Spring Boot&lt;/li>
&lt;li>Scripting: Python and R for analytics tasks&lt;/li>
&lt;li>Frontend: Angular for user interface&lt;/li>
&lt;/ul>
&lt;h2 id="understanding-bpmn">Understanding BPMN&lt;/h2>
&lt;p>&lt;a href="(https://en.wikipedia.org/wiki/Business_Process_Model_and_Notation)">Business Process Model and Notation (BPMN)&lt;/a> provided the foundation for our automation approach. BPMN, a graphical notation standard for business processes, was extended to accommodate automated pipelines and human-in-the-loop processes.&lt;/p></description></item></channel></rss>