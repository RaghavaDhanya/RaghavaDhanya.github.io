<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Mlops on AI Logs</title><link>https://ai.ragv.in/tags/mlops/</link><description>Recent content in Mlops on AI Logs</description><generator>Hugo -- 0.140.2</generator><language>en-us</language><copyright>2023 Raghava Dhanya | License |</copyright><lastBuildDate>Wed, 21 Feb 2024 12:25:03 +0530</lastBuildDate><atom:link href="https://ai.ragv.in/tags/mlops/index.xml" rel="self" type="application/rss+xml"/><item><title>A Tale of a Suicidal Container</title><link>https://ai.ragv.in/posts/a-tale-of-suicidal-container/</link><pubDate>Wed, 21 Feb 2024 12:25:03 +0530</pubDate><guid>https://ai.ragv.in/posts/a-tale-of-suicidal-container/</guid><description>&lt;p>One fine day, I sat down to optimize the size of a Docker image. Like many times before, I opted for &lt;a href="https://github.com/GoogleContainerTools/distroless">distroless&lt;/a> images as my base, a choice I had made countless times before without a hitch.&lt;/p>
&lt;p>Distroless images, for the uninitiated, are peak minimalism, containing only the essential libraries and binaries required to run the application. Not only do they trim the fat off the image size, but they also mitigate the risk of &lt;a href="https://www.cve.org/About/Overview">CVEs&lt;/a> lurking within.&lt;/p></description></item><item><title>Designing Machine Learning Systems for High Velocity Trading</title><link>https://ai.ragv.in/posts/high-velocity-trading-ml-systems/</link><pubDate>Tue, 20 Jun 2023 21:31:48 +0530</pubDate><guid>https://ai.ragv.in/posts/high-velocity-trading-ml-systems/</guid><description>&lt;p>As one of my works at &lt;a href="https://www.mu-sigma.com/labs">Mu Sigma Labs&lt;/a>, I was part of a research project on the High Velocity Time Series on early 2019. One of the goals was to create a high velocity trading app using Pair Trading.&lt;/p>
&lt;h2 id="the-requisite-terms">The Requisite terms&lt;/h2>
&lt;h3 id="long-and-short-trades">Long and Short trades&lt;/h3>
&lt;p>Long trades are buying a &lt;a href="https://en.wikipedia.org/wiki/Security_(finance)">security&lt;/a>. Short is selling a security even when you don&amp;rsquo;t own it. It generally means that you are borrowing someone&amp;rsquo;s securities and selling them in the hopes of buying it back for lower cost later and returning it and hence, making a profit. You don&amp;rsquo;t really have to do it though; exchanges take care of it and let you sell when you don&amp;rsquo;t own a security.&lt;/p></description></item><item><title>Python with a Dash of C++: Optimizing Recommendation Serving</title><link>https://ai.ragv.in/posts/python-with-a-dash-of-cpp-optimizing/</link><pubDate>Thu, 30 Jun 2022 16:54:09 +0530</pubDate><guid>https://ai.ragv.in/posts/python-with-a-dash-of-cpp-optimizing/</guid><description>&lt;p>Serving recommendation to 200+ millions of users for thousands of candidates with less than 100ms is &lt;strong>hard&lt;/strong> but doing that in Python is &lt;strong>harder&lt;/strong>. Why not add some compiled spice to it to make it faster? Using Cython you can add C++ components to your Python code. Isn&amp;rsquo;t all machine learning and statistics libraries already written in C and Cython to make them super fast? Yes. But there&amp;rsquo;s still some optimizations left on the table. I&amp;rsquo;ll go through how I optimized some of our sampling methods in the recommendation system using C++.&lt;/p></description></item><item><title>Go faster with Go: Golang for ML Serving</title><link>https://ai.ragv.in/posts/golang-for-machine-learning-serving/</link><pubDate>Mon, 20 Jun 2022 21:36:00 +0530</pubDate><guid>https://ai.ragv.in/posts/golang-for-machine-learning-serving/</guid><description>&lt;p>So the ask is to do &lt;strong>3 Million Predictions per second&lt;/strong> with as little resources as possible. Thankfully its one of the simpler model of Recommendation systems, Multi Armed Bandit(MAB).
Multi Armed bandit usually involves sampling from distribution like &lt;a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta Distribution&lt;/a>. That&amp;rsquo;s where the most time is spent. If we can concurrently do as many sampling as we can, we&amp;rsquo;ll use the resources well. Maximizing Resource utilization is the key to reducing overall resources needed for the model.&lt;/p></description></item><item><title>Showcase: BPMN Pipeline Platform</title><link>https://ai.ragv.in/posts/bpmn-pipeline-platform/</link><pubDate>Mon, 20 Jun 2022 20:54:07 +0530</pubDate><guid>https://ai.ragv.in/posts/bpmn-pipeline-platform/</guid><description>&lt;p>At &lt;a href="https://www.mu-sigma.com/labs">Mu Sigma Labs&lt;/a>, I led a significant project focused on BPMN-based analytics automation and pipeline orchestration. Using the open-source platform &lt;a href="https://www.activiti.org/">Activiti&lt;/a>, I owned, developed, tested, and maintained a system serving about &lt;em>3,000&lt;/em> internal users, handling &lt;em>critical&lt;/em> reporting and data pipelines.&lt;/p>
&lt;h3 id="technologies-used">Technologies Used&lt;/h3>
&lt;p>The core technologies employed were:&lt;/p>
&lt;ul>
&lt;li>Backend: Java and Spring Boot&lt;/li>
&lt;li>Scripting: Python and R for analytics tasks&lt;/li>
&lt;li>Frontend: Angular for user interface&lt;/li>
&lt;/ul>
&lt;h2 id="understanding-bpmn">Understanding BPMN&lt;/h2>
&lt;p>&lt;a href="(https://en.wikipedia.org/wiki/Business_Process_Model_and_Notation)">Business Process Model and Notation (BPMN)&lt;/a> provided the foundation for our automation approach. BPMN, a graphical notation standard for business processes, was extended to accommodate automated pipelines and human-in-the-loop processes.&lt;/p></description></item></channel></rss>