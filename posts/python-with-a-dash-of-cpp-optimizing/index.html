<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Python with a Dash of C++: Optimizing Recommendation Serving | AI Logs</title>
<meta name=keywords content="mlops,multi-armed-bandit,python,ml,ai,cython,c++"><meta name=description content="Serving recommendation to 200+ millions of users for thousands of candidates with less than 100ms is hard but doing that in Python is harder. Why not add some compiled spice to it to make it faster? Using Cython you can add C++ components to your Python code. Isn&rsquo;t all machine learning and statistics libraries already written in C and Cython to make them super fast? Yes. But there&rsquo;s still some optimizations left on the table."><meta name=author content="Raghava Dhanya"><link rel=canonical href=https://ai.ragv.in/posts/python-with-a-dash-of-cpp-optimizing/><link crossorigin=anonymous href=/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://ai.ragv.in/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ai.ragv.in/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ai.ragv.in/favicon-32x32.png><link rel=apple-touch-icon href=https://ai.ragv.in/apple-touch-icon.png><link rel=mask-icon href=https://ai.ragv.in/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ai.ragv.in/posts/python-with-a-dash-of-cpp-optimizing/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-RGHWYFE1WN"></script><script>var dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-RGHWYFE1WN",{anonymize_ip:!0})}</script><meta property="og:title" content="Python with a Dash of C++: Optimizing Recommendation Serving"><meta property="og:description" content="Serving recommendation to 200+ millions of users for thousands of candidates with less than 100ms is hard but doing that in Python is harder. Why not add some compiled spice to it to make it faster? Using Cython you can add C++ components to your Python code. Isn&rsquo;t all machine learning and statistics libraries already written in C and Cython to make them super fast? Yes. But there&rsquo;s still some optimizations left on the table."><meta property="og:type" content="article"><meta property="og:url" content="https://ai.ragv.in/posts/python-with-a-dash-of-cpp-optimizing/"><meta property="og:image" content="https://ai.ragv.in/images/python-with-a-dash-of-cpp-optimizing/cpp_python1.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-06-30T16:54:09+05:30"><meta property="article:modified_time" content="2022-06-30T16:54:09+05:30"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://ai.ragv.in/images/python-with-a-dash-of-cpp-optimizing/cpp_python1.png"><meta name=twitter:title content="Python with a Dash of C++: Optimizing Recommendation Serving"><meta name=twitter:description content="Serving recommendation to 200+ millions of users for thousands of candidates with less than 100ms is hard but doing that in Python is harder. Why not add some compiled spice to it to make it faster? Using Cython you can add C++ components to your Python code. Isn&rsquo;t all machine learning and statistics libraries already written in C and Cython to make them super fast? Yes. But there&rsquo;s still some optimizations left on the table."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://ai.ragv.in/posts/"},{"@type":"ListItem","position":2,"name":"Python with a Dash of C++: Optimizing Recommendation Serving","item":"https://ai.ragv.in/posts/python-with-a-dash-of-cpp-optimizing/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Python with a Dash of C++: Optimizing Recommendation Serving","name":"Python with a Dash of C\u002b\u002b: Optimizing Recommendation Serving","description":"Serving recommendation to 200+ millions of users for thousands of candidates with less than 100ms is hard but doing that in Python is harder. Why not add some compiled spice to it to make it faster? Using Cython you can add C++ components to your Python code. Isn\u0026rsquo;t all machine learning and statistics libraries already written in C and Cython to make them super fast? Yes. But there\u0026rsquo;s still some optimizations left on the table.","keywords":["mlops","multi-armed-bandit","python","ml","ai","cython","c++"],"articleBody":"Serving recommendation to 200+ millions of users for thousands of candidates with less than 100ms is hard but doing that in Python is harder. Why not add some compiled spice to it to make it faster? Using Cython you can add C++ components to your Python code. Isn’t all machine learning and statistics libraries already written in C and Cython to make them super fast? Yes. But there’s still some optimizations left on the table. I’ll go through how I optimized some of our sampling methods in the recommendation system using C++.\nMulti Armed Bandit(MAB) is one of the simpler models in our arsenal, it generally comes down to sampling from Beta distribution or a related distribution using specific distribution parameters for each user and candidate. So recommending for a user is mostly sampling thousands of times from thousands of distributions with different parameters.\nLet’s start with a simple sampling code, this is representative of what I started with, before any optimizations.\nfrom scipy.stats import beta samples = [ beta.rvs(a, b, random_state=25) for a,b in ab_vals.values] Let’s time it for 158k A and B values, sampled from our production data. Realistically we’ll never have to do so many sampling in a single request, but for better comparison in metrics I am using a large number of A and B values. Oh, that’s a lot of time. I hear Numpy is faster than Scipy. Let’s try with Numpy.\nimport numpy as np samples = [ np.random.beta(a, b) for a,b in ab_vals.values ] That’s 100x faster!. But I had an issue, there was a need to do Percent Point Function(PPF) calculation down the line. Numpy doesn’t support it, so I ended up looking for a better solution. And all these executions are running serially, even though Numpy is built in C and is well optimized we are coming back to Python after each sample. If we could somehow do the sampling in a batch using multiple cores, we can achieve better results.\nCython and C++ Cython can help you get away from GIL limitation and run functions in batch, but these functions can only be a pure Cython function or a C/C++ function. I don’t think I am big brain enough to build my own Beta sample and random number generator in Cython. So I went with writing these in C++ with the existing boost library.\nLet’s start with writing simple Beta sample function in C++\nbeta_dist_cpp.cpp\n#include #include #include #include double beta_sample(double alpha, double beta, long random){ boost::random::mt19937 generator(random); boost::random::beta_distribution\u003cdouble\u003e beta_random_dist(alpha, beta); double random_from_beta = beta_random_dist(generator); return random_from_beta; } //parameters and the random value on (0,1) you drew int main(){ double a = 1; double b = 2; int random = 25; std::cout\u003c\u003c\"Beta for \"\u003c\u003ca\u003c\u003c\", \"\u003c\u003cb\u003c\u003c \" Random:\"\u003c\u003crandom\u003c\u003c\" is \"\u003c\u003c beta_sample(a,b,random); } So from our old Scipy code, we were calling rvs with a random state. From its docs, we can see its creating Numpy’s RandomState from that number. Which is a container for Mersenne Twister. This is what our first line in our C++ function is doing, setting up a mersenne twister (pseudo) random number generator. The next line is creating beta distribution using A and B values. Boost has two implementations of Beta distribution. One in boost::random another in boost::math. The first is used for random sampling, that is what we want to do, the second for other statistics like PPF, Kurtosis etc. We need the second one too for calculating PPF but I’m not including that in this example (refer docs to see how to do it). The 3rd line is actually doing the sampling, I referred to this stackoverflow answer to understand how to sample in boost.\nBuilding the C++ code, make sure you have boost installed.\n$ g++ -o beta_dist.out beta_dist_cpp.cpp -I/usr/local/include/boost $ ./beta_dist.out Beta for 1, 2 Random:25 is 0.371978 That’s it. We have pure C++ function that we can parallelize in Cython. Let’s write a Cython wrapper and build into Python importable function\nExtract out headers into\nbeta_dist.hpp\n#ifndef BETA_DIST_H #define BETA_DIST_H #include #include #include #include double beta_sample(double, double , long); #endif beta_dist.pyx\n#!python #cython: language_level=3 import numpy as np from cython.parallel import prange cimport cython cdef extern from \"beta_dist.hpp\" nogil: double beta_sample(double, double , long) @cython.boundscheck(False) @cython.wraparound(False) def beta_sample_batch(double[:] a, double[:] b, long[:] random): cdef int N = len(a) cdef double[:] Y = np.zeros(N) cdef int i for i in prange(N, nogil=True): Y[i] = beta_sample(a[i], b[i], random[i]) return Y In the wrapper pyx we are importing the beta_sample from C++ and writing a pure Cython function that takes 3 vectors and runs beta_sample for them in parallel using prange. prange also takes number of threads as input, if not passed it takes it from OMP_NUM_THREADS or defaults to number of CPU cores.\nYou’ll need a setup.py to build the C++ and Cython code to make it importable in Python\nsetup.py\nfrom distutils.core import setup from Cython.Build import cythonize from distutils.extension import Extension from Cython.Distutils import build_ext import pathlib module_path = pathlib.Path(__file__).parent.resolve() ext_modules = [ Extension(\"beta_dist\", [str(module_path/\"beta_dist.pyx\"), str(module_path/\"beta_dist_cpp.cpp\")], libraries=[\"m\"], include_dirs=[\"/usr/local/include/boost\"], library_dirs=[\"/usr/local/lib\"], extra_compile_args = [\"-O3\", \"-ffast-math\", \"-march=native\", \"-fopenmp\" ], extra_link_args=['-fopenmp'], language=\"c++\") ] temp_build = module_path/\"build\" setup( name=\"beta_dist\", cmdclass = {'build_ext': build_ext}, ext_modules=ext_modules, script_name = 'setup.py', script_args = ['build_ext', f'--build-lib={module_path}', f'--build-temp={temp_build}'], ) Build the Cython extensions. Make sure you have Cython. You might also have to install OpenMP if you are not using GCC.\npython setup.py build_ext --inplace Let’s see what’s the improvement is\nfrom beta_dist import beta_sample_batch random = np.random.randint(low=0, high=1000, size=158208) samples = beta_sample_batch(ab_vals.a.values,ab_vals.b.values, random) That’s 3x faster than even our Numpy run on a 4 core machine while retaining the ability to add PPF calculation (I did add it and results were pretty much the same). Since its using all cores, it’ll be even better on larger machines.\nSo overall we were able to achieve 340x speedup from Scipy code while retaining all the capability of the Scipy code.\nThat’s it? Why not go ham and implement pre and post processing in Cython as well? Shiv did it. That’s not ham enough, why not implement the whole model in a compiled language? We did that too. Golang, Rust.\n","wordCount":"1023","inLanguage":"en","image":"https://ai.ragv.in/images/python-with-a-dash-of-cpp-optimizing/cpp_python1.png","datePublished":"2022-06-30T16:54:09+05:30","dateModified":"2022-06-30T16:54:09+05:30","author":{"@type":"Person","name":"Raghava Dhanya"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://ai.ragv.in/posts/python-with-a-dash-of-cpp-optimizing/"},"publisher":{"@type":"Organization","name":"AI Logs","logo":{"@type":"ImageObject","url":"https://ai.ragv.in/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ai.ragv.in/ accesskey=h title="AI Logs (Alt + H)"><img src=https://ai.ragv.in/Logo_2_0.svg alt=logo aria-label=logo height=30>AI Logs</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://ai.ragv.in/categories/ title=categories><span>categories</span></a></li><li><a href=https://ai.ragv.in/categories/projects/ title=projects><span>projects</span></a></li><li><a href=https://ai.ragv.in/tags/ title=tags><span>tags</span></a></li><li><a href=https://ragv.in title=ragv.in><span>ragv.in</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://ai.ragv.in/>Home</a>&nbsp;»&nbsp;<a href=https://ai.ragv.in/posts/>Posts</a></div><h1 class=post-title>Python with a Dash of C++: Optimizing Recommendation Serving</h1><div class=post-meta>&lt;span title='2022-06-30 16:54:09 +0530 +0530'>June 30, 2022&lt;/span>&amp;nbsp;·&amp;nbsp;5 min&amp;nbsp;·&amp;nbsp;Raghava Dhanya</div></header><figure class=entry-cover><img loading=lazy src=https://ai.ragv.in/images/python-with-a-dash-of-cpp-optimizing/cpp_python1.png alt="A blue and yellow python wrapped around C++ logo"><p>Python on C++ Illustration</p></figure><div class=post-content><p>Serving recommendation to 200+ millions of users for thousands of candidates with less than 100ms is <strong>hard</strong> but doing that in Python is <strong>harder</strong>. Why not add some compiled spice to it to make it faster? Using Cython you can add C++ components to your Python code. Isn&rsquo;t all machine learning and statistics libraries already written in C and Cython to make them super fast? Yes. But there&rsquo;s still some optimizations left on the table. I&rsquo;ll go through how I optimized some of our sampling methods in the recommendation system using C++.</p><p><a href=https://en.wikipedia.org/wiki/Multi-armed_bandit>Multi Armed Bandit(MAB)</a> is one of the simpler models in our arsenal, it generally comes down to sampling from Beta distribution or a related distribution using specific distribution parameters for each user and candidate. So recommending for a user is mostly sampling thousands of times from thousands of distributions with different parameters.</p><p>Let&rsquo;s start with a simple sampling code, this is representative of what I started with, before any optimizations.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> scipy.stats <span style=color:#f92672>import</span> beta
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>samples <span style=color:#f92672>=</span> [ beta<span style=color:#f92672>.</span>rvs(a, b, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>25</span>) <span style=color:#66d9ef>for</span> a,b <span style=color:#f92672>in</span> ab_vals<span style=color:#f92672>.</span>values]
</span></span></code></pre></div><p>Let&rsquo;s time it for <strong>158k</strong> A and B values, sampled from our production data. Realistically we&rsquo;ll never have to do so many sampling in a single request, but for better comparison in metrics I am using a large number of A and B values.
<img loading=lazy src=/images/python-with-a-dash-of-cpp-optimizing/timeit-scipy.png alt="screenshot of scipy time-it with 31.5 s ± 301 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)">
Oh, that&rsquo;s a lot of time. I hear Numpy is faster than Scipy. Let&rsquo;s try with Numpy.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>samples <span style=color:#f92672>=</span> [ np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>beta(a, b) <span style=color:#66d9ef>for</span> a,b <span style=color:#f92672>in</span> ab_vals<span style=color:#f92672>.</span>values ]
</span></span></code></pre></div><p><img loading=lazy src=/images/python-with-a-dash-of-cpp-optimizing/timeit-numpy.png alt="screenshot of numpy time-it with 290 ms ± 1.28 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"></p><p>That&rsquo;s <strong>100x</strong> faster!. But I had an issue, there was a need to do <a href=https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.ppf.html>Percent Point Function(PPF)</a> calculation down the line. Numpy doesn&rsquo;t support it, so I ended up looking for a better solution. And all these executions are running serially, even though Numpy is built in C and is well optimized we are coming back to Python after each sample. If we could somehow do the sampling in a batch using multiple cores, we can achieve better results.</p><h2 id=cython-and-c>Cython and C++<a hidden class=anchor aria-hidden=true href=#cython-and-c>#</a></h2><p>Cython can help you get away from GIL limitation and run functions in batch, but these functions can only be a pure Cython function or a C/C++ function. I don&rsquo;t think I am big brain enough to build my own Beta sample and random number generator in Cython. So I went with writing these in C++ with the existing <a href=https://www.boost.org/>boost</a> library.</p><p>Let&rsquo;s start with writing simple Beta sample function in C++</p><p><code>beta_dist_cpp.cpp</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;boost/math/distributions.hpp&gt;</span><span style=color:#75715e> 
</span></span></span><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;boost/random.hpp&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;iostream&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;random&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>double</span> <span style=color:#a6e22e>beta_sample</span>(<span style=color:#66d9ef>double</span> alpha, <span style=color:#66d9ef>double</span> beta, <span style=color:#66d9ef>long</span> random){
</span></span><span style=display:flex><span>    boost<span style=color:#f92672>::</span>random<span style=color:#f92672>::</span>mt19937 generator(random);
</span></span><span style=display:flex><span>    boost<span style=color:#f92672>::</span>random<span style=color:#f92672>::</span>beta_distribution<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>double</span><span style=color:#f92672>&gt;</span> beta_random_dist(alpha, beta);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>double</span> random_from_beta <span style=color:#f92672>=</span> beta_random_dist(generator);
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> random_from_beta;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span><span style=color:#75715e>//parameters and the random value on (0,1) you drew  
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>(){
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>double</span> a <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>double</span> b <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> random <span style=color:#f92672>=</span> <span style=color:#ae81ff>25</span>;
</span></span><span style=display:flex><span>    std<span style=color:#f92672>::</span>cout<span style=color:#f92672>&lt;&lt;</span><span style=color:#e6db74>&#34;Beta for &#34;</span><span style=color:#f92672>&lt;&lt;</span>a<span style=color:#f92672>&lt;&lt;</span><span style=color:#e6db74>&#34;, &#34;</span><span style=color:#f92672>&lt;&lt;</span>b<span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34; Random:&#34;</span><span style=color:#f92672>&lt;&lt;</span>random<span style=color:#f92672>&lt;&lt;</span><span style=color:#e6db74>&#34; is &#34;</span><span style=color:#f92672>&lt;&lt;</span> beta_sample(a,b,random);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>So from our old Scipy code, we were calling <a href=https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.rvs.html#scipy.stats.rv_continuous.rvs><code>rvs</code></a> with a random state. From its docs, we can see its creating Numpy&rsquo;s <a href=https://numpy.org/devdocs/reference/random/legacy.html#numpy.random.RandomState>RandomState</a> from that number. Which is a container for <a href=https://en.wikipedia.org/wiki/Mersenne_Twister>Mersenne Twister</a>. This is what our first line in our C++ function is doing, setting up a mersenne twister (pseudo) random number generator. The next line is creating beta distribution using A and B values. Boost has two implementations of Beta distribution. One in <a href=https://www.boost.org/doc/libs/1_79_0/doc/html/boost/random/beta_distribution.html><code>boost::random</code></a> another in <a href=https://www.boost.org/doc/libs/1_79_0/libs/math/doc/html/math_toolkit/dist_ref/dists/beta_dist.html><code>boost::math</code></a>. The first is used for random sampling, that is what we want to do, the second for other statistics like PPF, Kurtosis etc. We need the second one too for calculating PPF but I&rsquo;m not including that in this example (refer <a href=https://www.boost.org/doc/libs/1_43_0/libs/math/doc/sf_and_dist/html/math_toolkit/dist/dist_ref/nmp.html#math_toolkit.dist.dist_ref.nmp.quantile>docs</a> to see how to do it). The 3rd line is actually doing the sampling, I referred to this <a href=https://stackoverflow.com/a/52543195/4755194>stackoverflow answer</a> to understand how to sample in boost.</p><p>Building the C++ code, make sure you have <a href=https://www.boost.org/doc/libs/1_79_0/more/getting_started/index.html>boost installed</a>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ g++ -o beta_dist.out beta_dist_cpp.cpp -I/usr/local/include/boost
</span></span><span style=display:flex><span>$ ./beta_dist.out 
</span></span><span style=display:flex><span>Beta <span style=color:#66d9ef>for</span> 1, <span style=color:#ae81ff>2</span> Random:25 is 0.371978
</span></span></code></pre></div><p>That&rsquo;s it. We have pure C++ function that we can parallelize in Cython. Let&rsquo;s write a Cython wrapper and build into Python importable function</p><p>Extract out headers into</p><p><code>beta_dist.hpp</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=display:flex><span><span style=color:#75715e>#ifndef BETA_DIST_H
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define BETA_DIST_H
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;boost/math/distributions.hpp&gt;</span><span style=color:#75715e> 
</span></span></span><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;boost/random.hpp&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;iostream&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;random&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>double</span> <span style=color:#a6e22e>beta_sample</span>(<span style=color:#66d9ef>double</span>, <span style=color:#66d9ef>double</span> , <span style=color:#66d9ef>long</span>);
</span></span><span style=display:flex><span><span style=color:#75715e>#endif
</span></span></span></code></pre></div><p><code>beta_dist.pyx</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e>#!python</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#cython: language_level=3</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> cython.parallel <span style=color:#f92672>import</span> prange
</span></span><span style=display:flex><span>cimport cython
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cdef extern <span style=color:#f92672>from</span> <span style=color:#e6db74>&#34;beta_dist.hpp&#34;</span> nogil:
</span></span><span style=display:flex><span>    double beta_sample(double, double , long)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@cython.boundscheck</span>(<span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span><span style=color:#a6e22e>@cython.wraparound</span>(<span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>beta_sample_batch</span>(double[:] a, double[:] b, long[:] random):
</span></span><span style=display:flex><span>    cdef int N <span style=color:#f92672>=</span> len(a)
</span></span><span style=display:flex><span>    cdef double[:] Y <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros(N)
</span></span><span style=display:flex><span>    cdef int i
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> prange(N, nogil<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>):
</span></span><span style=display:flex><span>        Y[i] <span style=color:#f92672>=</span> beta_sample(a[i], b[i], random[i])
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> Y
</span></span></code></pre></div><p>In the wrapper <code>pyx</code> we are importing the beta_sample from C++ and writing a pure Cython function that takes 3 vectors and runs beta_sample for them in parallel using <a href=https://cython.readthedocs.io/en/latest/src/userguide/parallelism.html><code>prange</code></a>. <code>prange</code> also takes number of threads as input, if not passed it takes it from OMP_NUM_THREADS or defaults to number of CPU cores.</p><p>You&rsquo;ll need a <code>setup.py</code> to build the C++ and Cython code to make it importable in Python</p><p><code>setup.py</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> distutils.core <span style=color:#f92672>import</span> setup
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> Cython.Build <span style=color:#f92672>import</span> cythonize
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> distutils.extension <span style=color:#f92672>import</span> Extension
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> Cython.Distutils <span style=color:#f92672>import</span> build_ext
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pathlib
</span></span><span style=display:flex><span>module_path <span style=color:#f92672>=</span> pathlib<span style=color:#f92672>.</span>Path(__file__)<span style=color:#f92672>.</span>parent<span style=color:#f92672>.</span>resolve()
</span></span><span style=display:flex><span>ext_modules <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>        Extension(<span style=color:#e6db74>&#34;beta_dist&#34;</span>,
</span></span><span style=display:flex><span>            [str(module_path<span style=color:#f92672>/</span><span style=color:#e6db74>&#34;beta_dist.pyx&#34;</span>), str(module_path<span style=color:#f92672>/</span><span style=color:#e6db74>&#34;beta_dist_cpp.cpp&#34;</span>)],
</span></span><span style=display:flex><span>            libraries<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;m&#34;</span>],
</span></span><span style=display:flex><span>            include_dirs<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;/usr/local/include/boost&#34;</span>],
</span></span><span style=display:flex><span>            library_dirs<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;/usr/local/lib&#34;</span>],
</span></span><span style=display:flex><span>            extra_compile_args <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;-O3&#34;</span>, <span style=color:#e6db74>&#34;-ffast-math&#34;</span>, <span style=color:#e6db74>&#34;-march=native&#34;</span>, <span style=color:#e6db74>&#34;-fopenmp&#34;</span> ],
</span></span><span style=display:flex><span>            extra_link_args<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;-fopenmp&#39;</span>],
</span></span><span style=display:flex><span>            language<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;c++&#34;</span>)
</span></span><span style=display:flex><span>        ]
</span></span><span style=display:flex><span>temp_build <span style=color:#f92672>=</span> module_path<span style=color:#f92672>/</span><span style=color:#e6db74>&#34;build&#34;</span>
</span></span><span style=display:flex><span>setup(
</span></span><span style=display:flex><span>    name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;beta_dist&#34;</span>,
</span></span><span style=display:flex><span>    cmdclass <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;build_ext&#39;</span>: build_ext}, 
</span></span><span style=display:flex><span>    ext_modules<span style=color:#f92672>=</span>ext_modules,
</span></span><span style=display:flex><span>    script_name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;setup.py&#39;</span>,
</span></span><span style=display:flex><span>    script_args <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;build_ext&#39;</span>, <span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;--build-lib=</span><span style=color:#e6db74>{</span>module_path<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>, <span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;--build-temp=</span><span style=color:#e6db74>{</span>temp_build<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>],
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>Build the Cython extensions. Make sure you have <a href=https://pypi.org/project/Cython/>Cython</a>. You might also have to install OpenMP if you are not using GCC.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>python setup.py build_ext --inplace 
</span></span></code></pre></div><p>Let&rsquo;s see what&rsquo;s the improvement is</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> beta_dist <span style=color:#f92672>import</span> beta_sample_batch
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>random <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randint(low<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, high<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>, size<span style=color:#f92672>=</span><span style=color:#ae81ff>158208</span>)
</span></span><span style=display:flex><span>samples <span style=color:#f92672>=</span> beta_sample_batch(ab_vals<span style=color:#f92672>.</span>a<span style=color:#f92672>.</span>values,ab_vals<span style=color:#f92672>.</span>b<span style=color:#f92672>.</span>values, random)
</span></span></code></pre></div><p><img loading=lazy src=/images/python-with-a-dash-of-cpp-optimizing/timeit_cpp.png alt="screenshot of c++ time-it with 95.5 ms ± 554 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)"></p><p>That&rsquo;s <strong>3x</strong> faster than even our Numpy run on a 4 core machine while retaining the ability to add <a href=https://www.boost.org/doc/libs/1_43_0/libs/math/doc/sf_and_dist/html/math_toolkit/dist/dist_ref/nmp.html#math.dist.quantile>PPF</a> calculation (I did add it and results were pretty much the same). Since its using all cores, it&rsquo;ll be even better on larger machines.</p><p>So overall we were able to achieve <strong>340x</strong> speedup from Scipy code while retaining all the capability of the Scipy code.</p><p>That&rsquo;s it? Why not <a href=https://en.wiktionary.org/wiki/go_ham>go ham</a> and implement pre and post processing in Cython as well? <a href=http://shvbsle.in/computers-are-fast-but-you-dont-know-it-p1/>Shiv did it</a>. That&rsquo;s not ham enough, why not implement the whole model in a compiled language? We did that too. <a href=/posts/golang-for-machine-learning-serving>Golang</a>, <a href=http://shvbsle.in/serving-ml-at-the-speed-of-rust/>Rust</a>.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://ai.ragv.in/tags/mlops/>Mlops</a></li><li><a href=https://ai.ragv.in/tags/multi-armed-bandit/>Multi-Armed-Bandit</a></li><li><a href=https://ai.ragv.in/tags/python/>Python</a></li><li><a href=https://ai.ragv.in/tags/ml/>Ml</a></li><li><a href=https://ai.ragv.in/tags/ai/>Ai</a></li><li><a href=https://ai.ragv.in/tags/cython/>Cython</a></li><li><a href=https://ai.ragv.in/tags/c++/>C++</a></li></ul></footer></article></main><footer class=footer><span>© 2023 <a href=https://ragv.in>Raghava Dhanya</a> | <a href=/license>License</a> |</span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>